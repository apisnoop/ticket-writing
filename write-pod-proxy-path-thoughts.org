# -*- ii: apisnoop; -*-
#+TITLE: Write PodProxyWithPath Mock Test
#+AUTHOR: Stephen Heywood
#+TODO: TODO(t) NEXT(n) IN-PROGRESS(i) BLOCKED(b) | DONE(d)
#+OPTIONS: toc:nil tags:nil todo:nil
#+EXPORT_SELECT_TAGS: export
#+PROPERTY: header-args:sql-mode :product postgres

* The mock test                                                      :export:
** Test outline
1. Create a pod with a static label using the agnhost image

2. Confirm that the pod is in the running phase

3. Iterate through a list of http methods and check the response from the porter app

4. Confirm that each response code is 200 OK

** Test the functionality in Go
   #+NAME: Mock Test In Go
   #+begin_src go
     package main

     import (
       // "encoding/json"
       "context"
       "flag"
       "fmt"
       "net/http"
       "os"
       "time"

       v1 "k8s.io/api/core/v1"
       // "k8s.io/client-go/dynamic"
       // "k8s.io/apimachinery/pkg/runtime/schema"
       metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
       "k8s.io/apimachinery/pkg/util/wait"
       "k8s.io/client-go/kubernetes"
       "k8s.io/client-go/transport"
       // "k8s.io/apimachinery/pkg/types"
       "k8s.io/client-go/tools/clientcmd"
     )

     // helper function that mirrors framework.ExpectNoError
     func ExpectNoError(err error, msg string) {
       if err != nil {
         errMsg := msg + fmt.Sprintf(" %v\n", err)
         os.Stderr.WriteString(errMsg)
         os.Exit(1)
       }
     }

     // helper function that mirrors framework.ExpectEqual
     func ExpectEqual(a int, b int, msg string, i interface{}) {
       if a != b {
         errMsg := msg + fmt.Sprintf(" %v\n", i)
         os.Stderr.WriteString(errMsg)
         os.Exit(1)
       }
     }

     // helper function to inspect various interfaces
     func inspect(level int, name string, i interface{}) {
       fmt.Printf("Inspecting: %s\n", name)
       fmt.Printf("Inspect level: %d   Type: %T\n", level, i)
       switch level {
       case 1:
         fmt.Printf("%+v\n\n", i)
       case 2:
         fmt.Printf("%#v\n\n", i)
       default:
         fmt.Printf("%v\n\n", i)
       }
     }

     const (
       podRetryPeriod  = 1 * time.Second
       podRetryTimeout = 1 * time.Minute
     )

     func main() {
       // uses the current context in kubeconfig
       kubeconfig := flag.String("kubeconfig", fmt.Sprintf("%v/%v/%v", os.Getenv("HOME"), ".kube", "config"), "(optional) absolute path to the kubeconfig file")
       flag.Parse()
       config, err := clientcmd.BuildConfigFromFlags("", *kubeconfig)
       ExpectNoError(err, "Could not build config from flags")
       // make our work easier to find in the audit_event queries
       config.UserAgent = "live-test-writing"
       // creates the clientset
       ClientSet, _ := kubernetes.NewForConfig(config)
       // DynamicClientSet, _ := dynamic.NewForConfig(config)
       // podResource := schema.GroupVersionResource{Group: "", Version: "v1", Resource: "pods"}

       // TEST BEGINS HERE

       ns := "default" // f.Namespace.Name
       httpVerbs := []string{"DELETE", "GET", "HEAD", "OPTIONS", "PATCH", "POST", "PUT"}
       // httpVerbs := []string{"HEAD"}
       // httpVerbs := []string{"OPTIONS"}

       fmt.Println("Creating pod...")
       _, err = ClientSet.CoreV1().Pods(ns).Create(context.TODO(), &v1.Pod{
         ObjectMeta: metav1.ObjectMeta{
           Name: "agnhost",
           Labels: map[string]string{
             "test": "response"},
         },
         Spec: v1.PodSpec{
           Containers: []v1.Container{{
             Image:   "us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.21",
             Name:    "agnhost",
             Command: []string{"/agnhost", "porter"},
             Env: []v1.EnvVar{{
               Name:  "SERVE_PORT_80",
               Value: "foo",
             }},
           }},
           RestartPolicy: v1.RestartPolicyNever,
         }}, metav1.CreateOptions{})
       ExpectNoError(err, "failed to create pod")

       err = wait.PollImmediate(podRetryPeriod, podRetryTimeout, checkPodStatus(ClientSet, "test=response"))
       ExpectNoError(err, "Pod didn't start within time out period")

       transportCfg, err := config.TransportConfig()
       ExpectNoError(err, "Error creating transportCfg")
       restTransport, err := transport.New(transportCfg)
       ExpectNoError(err, "Error creating restTransport")

       client := &http.Client{
         CheckRedirect: func(req *http.Request, via []*http.Request) error {
           return http.ErrUseLastResponse
         },
         Transport: restTransport,
       }

       for _, httpVerb := range httpVerbs {

         urlString := config.Host + "/api/v1/namespaces/" + ns + "/pods/agnhost/proxy/some/path/with/" + httpVerb
         fmt.Printf("Starting http.Client for %s\n", urlString)
         request, err := http.NewRequest(httpVerb, urlString, nil)
         ExpectNoError(err, "processing request")

         resp, err := client.Do(request)
         ExpectNoError(err, "processing response")
         defer resp.Body.Close()

         fmt.Printf("http.Client request:%s StatusCode:%d\n", httpVerb, resp.StatusCode)
         ExpectEqual(resp.StatusCode, 200, "The resp.StatusCode returned: %d", resp.StatusCode)
       }

       // TEST ENDS HERE

       fmt.Println("[status] complete")

     }

     func checkPodStatus(cs *kubernetes.Clientset, label string) func() (bool, error) {
       return func() (bool, error) {
         var err error

         list, err := cs.CoreV1().Pods("default").List(context.TODO(), metav1.ListOptions{
           LabelSelector: label})

         if err != nil {
           return false, err
         }

         if list.Items[0].Status.Phase != "Running" {
           fmt.Printf("Pod Quantity: %d Status: %s\n", len(list.Items), list.Items[0].Status.Phase)
           return false, err
         }
         fmt.Printf("Pod Status: %v\n", list.Items[0].Status.Phase)
         return true, nil
       }
     }
   #+end_src

   #+RESULTS: Mock Test In Go
   #+begin_src go
   Creating pod...
   Pod Quantity: 1 Status: Pending
   Pod Quantity: 1 Status: Pending
   Pod Status: Running
   Starting http.Client for https://kubernetes.default/api/v1/namespaces/default/pods/agnhost/proxy/some/path/with/DELETE
   http.Client request:DELETE StatusCode:200
   Starting http.Client for https://kubernetes.default/api/v1/namespaces/default/pods/agnhost/proxy/some/path/with/GET
   http.Client request:GET StatusCode:200
   Starting http.Client for https://kubernetes.default/api/v1/namespaces/default/pods/agnhost/proxy/some/path/with/HEAD
   http.Client request:HEAD StatusCode:200
   Starting http.Client for https://kubernetes.default/api/v1/namespaces/default/pods/agnhost/proxy/some/path/with/OPTIONS
   http.Client request:OPTIONS StatusCode:200
   Starting http.Client for https://kubernetes.default/api/v1/namespaces/default/pods/agnhost/proxy/some/path/with/PATCH
   http.Client request:PATCH StatusCode:200
   Starting http.Client for https://kubernetes.default/api/v1/namespaces/default/pods/agnhost/proxy/some/path/with/POST
   http.Client request:POST StatusCode:200
   Starting http.Client for https://kubernetes.default/api/v1/namespaces/default/pods/agnhost/proxy/some/path/with/PUT
   http.Client request:PUT StatusCode:200
   [status] complete
   #+end_src

* Verifying increase in coverage with APISnoop                       :export:
** Reset stats

#+begin_src sql-mode :eval never-export :exports both :session none
delete from testing.audit_event;
#+end_src

#+RESULTS:
#+begin_SRC example
DELETE 34327
#+end_SRC

** Discover useragents:

  #+begin_src sql-mode :eval never-export :exports both :session none
    select distinct useragent
      from testing.audit_event
     where useragent like 'live%';
  #+end_src

  #+RESULTS:
  #+begin_SRC example
       useragent
  -------------------
   live-test-writing
  (1 row)

  #+end_SRC

** List endpoints hit by the test:

#+begin_src sql-mode :exports both :session none
  select * from testing.endpoint_hit_by_new_test ORDER BY hit_by_ete;
#+end_src

#+RESULTS:
#+begin_SRC example
     useragent     |                   endpoint                    | hit_by_ete | hit_by_new_test
-------------------+-----------------------------------------------+------------+-----------------
 live-test-writing | connectCoreV1PostNamespacedPodProxyWithPath   | f          |              12
 live-test-writing | connectCoreV1PatchNamespacedPodProxyWithPath  | f          |              15
 live-test-writing | connectCoreV1DeleteNamespacedPodProxyWithPath | f          |              15
 live-test-writing | connectCoreV1PutNamespacedPodProxyWithPath    | f          |              15
 live-test-writing | connectCoreV1GetNamespacedPodProxyWithPath    | t          |              27
 live-test-writing | listCoreV1NamespacedPod                       | t          |              50
 live-test-writing | createCoreV1NamespacedPod                     | t          |              19
(7 rows)

#+end_SRC

** Display endpoint coverage change:

  #+begin_src sql-mode :eval never-export :exports both :session none
    select * from testing.projected_change_in_coverage;
  #+end_src

  #+RESULTS:
  #+begin_SRC example
     category    | total_endpoints | old_coverage | new_coverage | change_in_number
  ---------------+-----------------+--------------+--------------+------------------
   test_coverage |             831 |          306 |          310 |                4
  (1 row)

  #+end_SRC

* Exploring / Questions about missing endpoints                      :export:

Where/How does PATCH/HEAD/OPTIONS requests for the following endpoints line up with the API reference?

- connectCoreV1PatchNamespacedPodProxyWithPath
- connectCoreV1HeadNamespacedPodProxyWithPath
- connectCoreV1OptionsNamespacedPodProxyWithPath

*Pod v1 core: Proxy Operations*

https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#-strong-proxy-operations-pod-v1-core-strong-

| httpVerb | Endpoint                   |
|----------+----------------------------|
| POST     | Create Connect Proxy       |
|          | Create Connect Proxy Path  |
| DELETE   | Delete Connect Proxy       |
|          | Delete Connect Proxy Path  |
| GET      | Get Connect Proxy          |
|          | Get Connect Proxy Path     |
| HEAD     | Head Connect Proxy         |
|          | Head Connect Proxy Path    |
| PUT      | Replace Connect Proxy      |
|          | Replace Connect Proxy Path |

* Locate why 2 endpoints are missing                                 :export:

https://apisnoop.cncf.io/conformance-progress/endpoints/1.9.0?filter=promotedWithoutTests&filter=untested shows the following endpoints are listed as valid endpoints;

- connectCoreV1HeadNamespacedPodProxyWithPath
- connectCoreV1OptionsNamespacedPodProxyWithPath

** Missing HEAD requests

These requests are getting logged as a =get= verb.

Line 24520: api/openapi-spec

#+begin_src json
      "head": {
        "consumes": [
          "*/*"
        ],
        "description": "connect HEAD requests to proxy of Pod",
        "operationId": "connectCoreV1HeadNamespacedPodProxyWithPath",
        "produces": [
          "*/*"
        ],
        "responses": {
          "200": {
            "description": "OK",
            "schema": {
              "type": "string"
            }
          },
          "401": {
            "description": "Unauthorized"
          }
        },
        "schemes": [
          "https"
        ],
        "tags": [
          "core_v1"
        ],
        "x-kubernetes-action": "connect",
        "x-kubernetes-group-version-kind": {
          "group": "",
          "kind": "PodProxyOptions",
          "version": "v1"
        }
#+end_src

** Missing OPTIONS requests

Line 24553: api/openapi-spec

#+begin_src json
      "options": {
        "consumes": [
          "*/*"
        ],
        "description": "connect OPTIONS requests to proxy of Pod",
        "operationId": "connectCoreV1OptionsNamespacedPodProxyWithPath",
        "produces": [
          "*/*"
        ],
        "responses": {
          "200": {
            "description": "OK",
            "schema": {
              "type": "string"
            }
          },
          "401": {
            "description": "Unauthorized"
          }
        },
        "schemes": [
          "https"
        ],
        "tags": [
          "core_v1"
        ],
        "x-kubernetes-action": "connect",
        "x-kubernetes-group-version-kind": {
          "group": "",
          "kind": "PodProxyOptions",
          "version": "v1"
        }
#+end_src

** Verbs missing

Looking at snoopUtils.py there doesn't look to be a mapping for the above methods.

#+begin_src python
VERB_TO_METHOD={
    'get': 'get',
    'list': 'get',
    'proxy': 'proxy',
    'create': 'post',
    'post':'post',
    'put':'post',
    'update':'put',
    'patch':'patch',
    'connect':'connect',
    'delete':'delete',
    'deletecollection':'delete',
    'watch':'get'
}
#+end_src

** Are these verbs in the audit logs?
   We know we hit them in our test, so they should appear in the list of verbs in our testing.audit_events

   #+begin_src sql-mode
     select distinct (data->>'verb') as "audit event verbs"
       from testing.audit_event;
   #+end_src

   #+RESULTS:
   #+begin_SRC example
    audit event verbs
   -------------------
    patch
    delete
    create
    get
    update
    watch
    list
   (7 rows)

   #+end_SRC

   What about the full test runs?

   #+begin_src sql-mode
     select distinct (data->>'verb')  as "audit event verbs"
       from audit_event;
   #+end_src

   #+RESULTS:
   #+begin_SRC example
    audit event verbs
   -------------------
    create
    delete
    deletecollection
    get
    list
    patch
    update
    watch
   (8 rows)

   #+end_SRC

** Our Data flow
   Audit events move into the snoop database like so:
   - something hits the kubernetes cluster that has auditing enabled, which creates an event
   - apisnoop/auditlogger listens to all events and inserts them into `testing.audit_event`
     it does so with the following values:
    #+begin_example js
      function logEventToDB (event) {
      // ...excerpt
          const {
              auditID,
              userAgent
          } = event

      // ...
          let dataToInsert = {
              release: 'live',
              release_date: Date.now().toString(),
              audit_id: auditID,
              useragent: userAgent,
              test: userAgent,
              test_hit:  STARTS_WITH_E2E.test(userAgent),
              conf_test_hit: HAS_CONF_IN_BRACKETS.test(userAgent),
              data: JSON.stringify(event),
              source: 'live'
          }
      //...not included: knex transation to insert into db, regex for testing if it a test hit
      }

    #+end_example

    what's important to note is that the auditlogger does not do any processing of the data.  It exctracts some values, but then puts the whole event in as the `data` column of our audit event table.
   - we have a sql trigger that processes the event before insertion
     - The trigger is this:
        #+BEGIN_example sql-mode
        create trigger add_endpoint
        before insert on testing.audit_event
        for each row
        execute procedure determine_endpoint();
        #+END_example

        with that determine_endpoint function being:
          #+BEGIN_SRC sql-mode
          create or replace function determine_endpoint() RETURNS TRIGGER as $$
            import json
            from snoopUtils import load_openapi_spec, find_operation_id
            CURRENT_SWAGGER_URL = "https://raw.githubusercontent.com/kubernetes/kubernetes/master/api/openapi-spec/swagger.json"
            if "spec" not in GD:
                GD["spec"] = load_openapi_spec(CURRENT_SWAGGER_URL)
            spec = GD["spec"]
            event = json.loads(TD["new"]["data"])
            if TD["new"]["endpoint"] is None:
                TD["new"]["endpoint"] = find_operation_id(spec, event);
            return "modify";
          $$ language plpython3u;
          #+END_SRC

          TD is the trigger dictionary, and so when we modify ~TD["new"]["endpoint"] it's adding an endpoint value to what will become the new record when the trigger calls.
          So the important part here is that the only part touched by our trigger is the endpoint field.
   - Adding the endpoint is done with snoopUtils, and the function ~find_operation_id~.
     - This is a v. long function so I won't include it here, but as you see in the ~determine_endpoint~ function, we pass along the raw data, as the *event* along with the open_api spec.
     - then in the function, we map the verbs to their corresponding api methods in the open api spec, since there's some differences between the two which makes a 1-to-1 map impossible.
     - if the event verb doesn't exist in this dictionary, we'd get an error.  But we never modify the verb itself.
** Why this dataflow is important
   We put the raw event into the data column, including the verb given in the audit log itself, and we do not modify this value.
    When we look at the verbs of events created during yr test:
    #+begin_src sql-mode
      select (data->>'verb') as "Audit Event Verbs"
         from testing.audit_event
          where useragent = 'live-test-writing'
         group by (data->>'verb');
    #+end_src

    #+RESULTS:
    #+begin_SRC example
     Audit Event Verbs
    -------------------
     create
     delete
     get
     list
     patch
     update
    (6 rows)

    #+end_SRC

    Neither ~head~ or ~option~ are here.  They are either not being audited or don't exist as verbs according to the audit log specification.
** Next steps
   I think we'd want to re-check the spec for the audit logs and see what value verbs can be.  If head and option are valid, then we'd want to look into our auditing config and see if they aren't being picked up at all.  If they are not valid, then we'd want to find some other way to find the head/option events transmitted and attach them to their correct operation_ids




      -
